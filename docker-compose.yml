version: '3.8'
services:
  ollama:
    image: ollama/ollama:latest
    ports:
      - 11434:11434
    environment:
      - OLLAMA_MODELS=${OLLAMA_MODELS}
      - OLLAMA_MODELS_PATH=${MODEL_DIR}/ollama
    command: >
      bash -c "
        set -e
        mkdir -p ${MODEL_DIR}/ollama
        ollama serve &
        sleep 5
        ollama pull $${OLLAMA_MODELS}
        wait
      "
    volumes:
      - ${MODEL_DIR}/ollama:/root/.ollama

  kokoro:
    image: ghcr.io/remsky/kokoro-fastapi:latest
    environment:
      - KOKORO_MODEL_PATH=${MODEL_DIR}/kokoro
      - KOKORO_MODEL=${KOKORO_MODEL}
    command: >
      bash -c "
        set -e
        mkdir -p ${MODEL_DIR}/kokoro
        python3 download_kokoro.py --model $${KOKORO_MODEL} --output ${MODEL_DIR}/kokoro
        uvicorn main:app --host 0.0.0.0 --port 8002
      "
    ports:
      - 8002:8000
    volumes:
      - ${MODEL_DIR}/kokoro:${MODEL_DIR}/kokoro

  whisper:
    image: ghcr.io/ggerganov/whisper.cpp:latest
    command: >
      bash -c "
        mkdir -p ${MODEL_DIR}/whisper;
        if [ ! -f ${MODEL_DIR}/whisper/${WHISPER_MODEL}.bin ]; then
          ./models/download-ggml-model.sh $${WHISPER_MODEL};
          mv ./models/$${WHISPER_MODEL}.bin ${MODEL_DIR}/whisper/;
        fi;
        ./main --model ${MODEL_DIR}/whisper/${WHISPER_MODEL}.bin --language ko --help
      "
    environment:
      - WHISPER_MODEL=${WHISPER_MODEL}
      - WHISPER_MODEL_PATH=${MODEL_DIR}/whisper
    volumes:
      - ${MODEL_DIR}/whisper:${MODEL_DIR}/whisper
    ports:
      - 8003:8080

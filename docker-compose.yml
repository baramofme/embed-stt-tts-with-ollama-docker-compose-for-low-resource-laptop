version: "3.9"
services:
  download_models:
    image: curlimages/curl:7.87.0
    entrypoint: ["/bin/sh","-c"]
    environment:
      - OLLAMA_MODELS=${OLLAMA_MODELS}
      - EMBEDDING_MODEL=${EMBEDDING_MODEL}
      - TTS_MODEL=${TTS_MODEL}
      - STT_MODEL=${STT_MODEL}
    volumes:
      - ${OLLAMA_MODELS}:/ollama_models
    command: |
      set -e
      mkdir -p "/ollama_models/models/library/${EMBEDDING_MODEL}/f16"
      mkdir -p "/ollama_models/models/library/${TTS_MODEL}/f16"
      mkdir -p "/ollama_models/models/library/${STT_MODEL}/f16"
      curl -L -o "/ollama_models/models/library/${EMBEDDING_MODEL}/f16/model" \
        https://ollama-models.jeffh.com/intfloat-multilingual-e5-large-instruct-f16.gguf
      curl -L -o "/ollama_models/models/library/${TTS_MODEL}/f16/model" \
        https://ollama-models.kokoroai.com/kokoro-82m-f16.gguf
      curl -L -o "/ollama_models/models/library/${STT_MODEL}/f16/model" \
        https://ollama-models.openai.com/whisper-base-f16.gguf

  ollama:
    image: ollama/ollama:latest
    environment:
      - OLLAMA_MODELS=/root/.ollama
    volumes:
      - ${OLLAMA_MODELS}:/root/.ollama
    ports:
      - "11434:11434"
    restart: unless-stopped
    depends_on:
      - download_models
    command: serve

  ollama-webui:
    image: ghcr.io/ollama-webui/ollama-webui:main
    environment:
      - OLLAMA_API_BASE_URL=http://ollama:11434
    ports:
      - "3000:8080"
    depends_on:
      - ollama
